{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (6.1.0)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (2.22.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (3.4.4)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (5.1.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (4.7.1)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.0)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from newspaper3k) (4.3.4)\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
      "Requirement already satisfied: six in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.24.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (1.8)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (41.0.1)\n",
      "Building wheels for collected packages: feedfinder2, tinysegmenter, jieba3k, feedparser\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\de\\03\\ca\\778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\81\\2b\\43\\a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\83\\15\\9c\\a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
      "  Building wheel for feedparser (setup.py): started\n",
      "  Building wheel for feedparser (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\8c\\69\\b7\\f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
      "Successfully built feedfinder2 tinysegmenter jieba3k feedparser\n",
      "Installing collected packages: feedfinder2, cssselect, tinysegmenter, requests-file, tldextract, jieba3k, feedparser, newspaper3k\n",
      "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/d3/5af102af577f57f706fcb302ea47d40e09355778488de904b3594d4e48d2/Scrapy-2.1.0-py2.py3-none-any.whl (239kB)\n",
      "Collecting PyDispatcher>=2.0.5 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
      "Collecting w3lib>=1.17.0 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from scrapy) (2.7)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from scrapy) (4.3.4)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Collecting Twisted>=17.9.0 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/b1/c1944ce7c2e42afc0ee8888df118d9691c5e446cf6fbb0ec1898f2bc0bc9/Twisted-20.3.0-cp37-cp37m-win_amd64.whl (3.1MB)\n",
      "Collecting parsel>=1.5.0 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/1e/9b39d64cbab79d4362cdd7be7f5e9623d45c4a53b3f7522cd8210df52d8e/parsel-1.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from scrapy) (19.0.0)\n",
      "Collecting service-identity>=16.0.0 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
      "Collecting queuelib>=1.4.2 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/85/ae64e9145f39dd6d14f8af3fa809a270ef3729f3b90b3c0cf5aa242ab0d4/queuelib-1.5.0-py2.py3-none-any.whl\n",
      "Collecting zope.interface>=4.1.3 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/f9/af181babed312b9e21271dbfd7ec0815f822a12aaa2fe472d98e62e5bac3/zope.interface-5.1.0-cp37-cp37m-win_amd64.whl (194kB)\n",
      "Collecting protego>=0.1.15 (from scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/6e/bf6d5e4d7cf233b785719aaec2c38f027b9c2ed980a0015ec1a1cced4893/Protego-0.1.16.tar.gz (3.2MB)\n",
      "Requirement already satisfied: six>=1.4.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from w3lib>=1.17.0->scrapy) (1.12.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (0.24.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.12.3)\n",
      "Collecting Automat>=0.3.0 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n",
      "Collecting attrs>=19.2.0 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/db/4313ab3be961f7a763066401fb77f7748373b6094076ae2bda2806988af6/attrs-19.3.0-py2.py3-none-any.whl\n",
      "Collecting constantly>=15.1 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
      "Collecting PyHamcrest!=1.10.0,>=1.9.0 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n",
      "Collecting hyperlink>=17.1.1 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/91/e916ca10a2de1cb7101a9b24da546fb90ee14629e23160086cf3361c4fb8/hyperlink-19.0.0-py2.py3-none-any.whl\n",
      "Collecting incremental>=16.10.1 (from Twisted>=17.9.0->scrapy)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (41.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.19)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.8)\n",
      "Building wheels for collected packages: PyDispatcher, protego\n",
      "  Building wheel for PyDispatcher (setup.py): started\n",
      "  Building wheel for PyDispatcher (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\88\\99\\96\\cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
      "  Building wheel for protego (setup.py): started\n",
      "  Building wheel for protego (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\shrikanth\\AppData\\Local\\pip\\Cache\\wheels\\51\\01\\d1\\4a2286a976dccd025ba679acacfe37320540df0f2283ecab12\n",
      "Successfully built PyDispatcher protego\n",
      "Installing collected packages: PyDispatcher, w3lib, attrs, Automat, constantly, zope.interface, PyHamcrest, hyperlink, incremental, Twisted, parsel, service-identity, queuelib, protego, scrapy\n",
      "  Found existing installation: attrs 19.1.0\n",
      "    Uninstalling attrs-19.1.0:\n",
      "      Successfully uninstalled attrs-19.1.0\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 PyHamcrest-2.0.2 Twisted-20.3.0 attrs-19.3.0 constantly-15.1.0 hyperlink-19.0.0 incremental-17.5.0 parsel-1.6.0 protego-0.1.16 queuelib-1.5.0 scrapy-2.1.0 service-identity-18.1.0 w3lib-1.22.0 zope.interface-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting validator-collection\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/8c/52fbb84e7f9b5b5da2251d598a40414ef04f963f4774b6b14ca94cbf51f0/validator_collection-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from validator-collection) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from jsonschema->validator-collection) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from jsonschema->validator-collection) (0.14.11)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from jsonschema->validator-collection) (41.0.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\shrikanth\\anaconda3\\lib\\site-packages (from jsonschema->validator-collection) (1.12.0)\n",
      "Installing collected packages: validator-collection\n",
      "Successfully installed validator-collection-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install validator-collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrikanth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from validator_collection import validators, checkers\n",
    "from urllib.request import urlopen\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from newspaper import Article\n",
    "import scrapy\n",
    "import requests\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_class_hrefs(url):\n",
    "    \"\"\"\n",
    "    Finds all urls pointed to by all links inside\n",
    "    'news' class div elements\n",
    "    \"\"\"\n",
    "    #https://stackoverflow.com/questions/36709165/beautifulsoup-object-of-type-response-has-no-len\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    #https://stackoverflow.com/questions/32468801/how-to-get-href-from-an-a-tag-inside-a-div\n",
    "    links = ['https://timesofindia.indiatimes.com'+a['href'] for div in soup.find_all(\"div\", attrs={\"class\": \"content\"}) for a in div.find_all('a')]\n",
    "    return links[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://timesofindia.indiatimes.com/india/bjps-virtual-political-campaign/articleshow/76025044.cms',\n",
       " 'https://timesofindia.indiatimes.comhttps://timesofindia.indiatimes.com/a-glimpse-of-amitabh-bachchans-illustrious-life/political-plunge/photostory/75025659.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/bengaluru/places-of-worship-gear-up-to-welcome-devotees-in-karnataka/articleshow/76241539.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/bengaluru/karnataka-hunt-on-to-find-bs-yediyurappas-successor/articleshow/76241457.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/rajkot/politics-sullies-corona-warriors-felicitation/articleshow/76329286.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/hyderabad/cong-cheap-politics-by-kcr/articleshow/75636801.cms',\n",
       " 'https://timesofindia.indiatimes.comhttps://timesofindia.indiatimes.com/life-style/spotlight/most-hilarious-whatsapp-messages-about-coronavirus-because-laughter-is-the-best-medicine/the-political-game/photostory/74654509.cms',\n",
       " 'https://timesofindia.indiatimes.comhttps://timesofindia.indiatimes.com/tv/news/hindi/exclusive-dipika-chikhlia-in-the-first-seven-days-of-ramayan-shoot-i-didnt-have-a-single-dialogue/on-her-political-career/photostory/75450022.cms',\n",
       " 'https://timesofindia.indiatimes.com/india/congress-is-creating-political-pollution-naqvi/articleshow/76004303.cms',\n",
       " 'https://timesofindia.indiatimes.com/india/how-politics-is-changing-office-politics/articleshow/73478429.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/lucknow/cases-against-lallu-politically-motivated/articleshow/75956897.cms',\n",
       " 'https://timesofindia.indiatimes.com/home/sunday-times/how-politics-is-changing-office-politics/articleshow/73423310.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/mysuru/will-not-bow-to-blackmail-politics-says-somashekar/articleshow/75871987.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/coimbatore/political-parties-condemn-state-government/articleshow/75611528.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/chennai/politics-over-a-pandemic-assails-tamil-nadu/articleshow/76436897.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/goa/lobo-accuses-khaunte-of-indulging-in-childish-politics/articleshow/76434384.cms',\n",
       " 'https://timesofindia.indiatimes.com/sports/football/top-stories/uefa-praises-players-for-taking-political-stance/articleshow/76430480.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/chandigarh/release-sikh-political-prisoners/articleshow/74882073.cms',\n",
       " 'https://timesofindia.indiatimes.com/city/goa/cm-playing-politics-with-volunteering/articleshow/74880067.cms']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_class_hrefs('https://timesofindia.indiatimes.com/topic/Politics/2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_details(url):\n",
    "    \n",
    "    try:\n",
    "        toi_article = Article(url, language=\"en\")\n",
    "        toi_article.download()\n",
    "        time.sleep(0.5)\n",
    "        toi_article.parse()\n",
    "        time.sleep(2)\n",
    "        toi_article.nlp()\n",
    "    \n",
    "        ArticleTitle = toi_article.title\n",
    "        ArticleText = toi_article.text\n",
    "        ArticleSummary = toi_article.summary\n",
    "        #ArtPubDate = toi_article.publish_date\n",
    "        return ArticleTitle, ArticleText, ArticleSummary\n",
    "\n",
    "    except ArticleException:\n",
    "        toi_article = Article(url, language=\"en\")\n",
    "        toi_article.download()\n",
    "        time.sleep(2)\n",
    "        toi_article.parse()\n",
    "        time.sleep(2)\n",
    "        toi_article.nlp()\n",
    "    \n",
    "        ArticleTitle = toi_article.title\n",
    "        ArticleText = toi_article.text\n",
    "        ArticleSummary = toi_article.summary\n",
    "        #ArtPubDate = toi_article.publish_date\n",
    "        return ArticleTitle, ArticleText, ArticleSummary\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total News Articles Scrapped = 17\n",
      "Total News Articles Scrapped = 33\n",
      "Total News Articles Scrapped = 49\n",
      "Total News Articles Scrapped = 65\n",
      "Total News Articles Scrapped = 81\n",
      "Total News Articles Scrapped = 97\n",
      "Total News Articles Scrapped = 113\n",
      "Total News Articles Scrapped = 129\n",
      "Total News Articles Scrapped = 145\n",
      "Total News Articles Scrapped = 161\n",
      "Total News Articles Scrapped = 177\n",
      "Total News Articles Scrapped = 193\n",
      "Total News Articles Scrapped = 209\n",
      "Total News Articles Scrapped = 225\n",
      "Total News Articles Scrapped = 241\n",
      "Total News Articles Scrapped = 257\n",
      "Total News Articles Scrapped = 273\n",
      "Total News Articles Scrapped = 289\n",
      "Total News Articles Scrapped = 305\n",
      "Total News Articles Scrapped = 321\n",
      "Total News Articles Scrapped = 337\n",
      "Total News Articles Scrapped = 353\n",
      "Total News Articles Scrapped = 369\n",
      "Total News Articles Scrapped = 385\n",
      "Total News Articles Scrapped = 401\n",
      "Total News Articles Scrapped = 417\n",
      "Total News Articles Scrapped = 433\n",
      "Total News Articles Scrapped = 449\n",
      "Total News Articles Scrapped = 465\n",
      "Total News Articles Scrapped = 481\n",
      "Total News Articles Scrapped = 497\n",
      "Total News Articles Scrapped = 513\n",
      "Total News Articles Scrapped = 529\n",
      "Total News Articles Scrapped = 545\n",
      "Total News Articles Scrapped = 561\n",
      "Total News Articles Scrapped = 577\n",
      "Total News Articles Scrapped = 593\n",
      "Total News Articles Scrapped = 609\n",
      "Total News Articles Scrapped = 625\n",
      "Total News Articles Scrapped = 641\n",
      "Total News Articles Scrapped = 657\n",
      "Total News Articles Scrapped = 673\n",
      "Total News Articles Scrapped = 689\n",
      "Total News Articles Scrapped = 705\n",
      "Total News Articles Scrapped = 721\n",
      "Total News Articles Scrapped = 737\n",
      "Total News Articles Scrapped = 753\n",
      "Total News Articles Scrapped = 769\n",
      "Total News Articles Scrapped = 785\n",
      "Total News Articles Scrapped = 801\n",
      "Total News Articles Scrapped = 817\n",
      "Total News Articles Scrapped = 833\n",
      "Total News Articles Scrapped = 849\n",
      "Total News Articles Scrapped = 865\n",
      "Total News Articles Scrapped = 881\n",
      "Total News Articles Scrapped = 897\n",
      "Total News Articles Scrapped = 913\n",
      "Total News Articles Scrapped = 929\n",
      "Total News Articles Scrapped = 945\n",
      "Total News Articles Scrapped = 961\n",
      "Total News Articles Scrapped = 977\n",
      "Total News Articles Scrapped = 993\n",
      "Total News Articles Scrapped = 1009\n",
      "Total News Articles Scrapped = 1025\n",
      "Total News Articles Scrapped = 1041\n",
      "Total News Articles Scrapped = 1057\n",
      "Total News Articles Scrapped = 1073\n",
      "Total News Articles Scrapped = 1089\n",
      "Total News Articles Scrapped = 1105\n",
      "Total News Articles Scrapped = 1121\n",
      "Total News Articles Scrapped = 1137\n",
      "Total News Articles Scrapped = 1153\n",
      "Total News Articles Scrapped = 1169\n",
      "Total News Articles Scrapped = 1185\n",
      "Total News Articles Scrapped = 1201\n",
      "Total News Articles Scrapped = 1217\n",
      "Total News Articles Scrapped = 1233\n",
      "Total News Articles Scrapped = 1249\n",
      "Total News Articles Scrapped = 1265\n",
      "Total News Articles Scrapped = 1281\n",
      "Total News Articles Scrapped = 1297\n",
      "Total News Articles Scrapped = 1313\n",
      "Total News Articles Scrapped = 1329\n",
      "Total News Articles Scrapped = 1345\n",
      "Total News Articles Scrapped = 1361\n",
      "Total News Articles Scrapped = 1377\n",
      "Total News Articles Scrapped = 1393\n",
      "Total News Articles Scrapped = 1409\n",
      "Total News Articles Scrapped = 1425\n",
      "Total News Articles Scrapped = 1441\n",
      "Total News Articles Scrapped = 1457\n",
      "Total News Articles Scrapped = 1473\n",
      "Total News Articles Scrapped = 1489\n",
      "Total News Articles Scrapped = 1505\n",
      "Total News Articles Scrapped = 1521\n",
      "Total News Articles Scrapped = 1537\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ArticleException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ab9dddb6702d>\u001b[0m in \u001b[0;36mget_news_details\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mtoi_article\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\newspaper\\article.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow_if_not_downloaded_verbose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\newspaper\\article.py\u001b[0m in \u001b[0;36mthrow_if_not_downloaded_verbose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    531\u001b[0m             raise ArticleException('Article `download()` failed with %s on URL %s' %\n\u001b[1;32m--> 532\u001b[1;33m                   (self.download_exception_msg, self.url))\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArticleException\u001b[0m: Article `download()` failed with HTTPSConnectionPool(host='timesofindia.indiatimes.com', port=443): Max retries exceeded with url: /city/mysuru/will-not-bow-to-blackmail-politics-says-somashekar/articleshow/75871987.cms (Caused by ConnectTimeoutError(<urllib3.connection.VerifiedHTTPSConnection object at 0x000000D1FE9D9DD8>, 'Connection to timesofindia.indiatimes.com timed out. (connect timeout=7)')) on URL https://timesofindia.indiatimes.com/city/mysuru/will-not-bow-to-blackmail-politics-says-somashekar/articleshow/75871987.cms",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5173ddf77378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0martLink\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mArtLinks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheckers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martLink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mTitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_news_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martLink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             temp_df = pd.DataFrame({'Title' : Title,\n\u001b[0;32m     14\u001b[0m                                     \u001b[1;34m'Text'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ab9dddb6702d>\u001b[0m in \u001b[0;36mget_news_details\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mArticleTitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArticleText\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArticleSummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[0mArticleException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mtoi_article\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtoi_article\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ArticleException' is not defined"
     ]
    }
   ],
   "source": [
    "TOI_Articles = pd.DataFrame(columns = ['Title', 'Text', 'Summary'])\n",
    "invalid_url, ArtTitle, ArtTest, ArtSummary, processedURLs = ([] for i in range(5))\n",
    "for i in range(20,500):\n",
    "    #https://timesofindia.indiatimes.com/topic/Politics\n",
    "    pageUrl = 'https://timesofindia.indiatimes.com/topic/Politics'+'/{}'.format(i)\n",
    "    processedURLs.append(pageUrl)\n",
    "    ArtLinks = get_news_class_hrefs(pageUrl)\n",
    "    \n",
    "    #https://stackoverflow.com/questions/23013220/max-retries-exceeded-with-url-in-requests\n",
    "    for artLink in ArtLinks:\n",
    "        if checkers.is_url(artLink):\n",
    "            Title, Text, Summary = get_news_details(artLink)\n",
    "            temp_df = pd.DataFrame({'Title' : Title,\n",
    "                                    'Text' : Text,\n",
    "                                    'Summary' : Summary}, index=[0])\n",
    "            TOI_Articles = TOI_Articles.append(temp_df, ignore_index=True, sort=True)\n",
    "            ArtTitle.append(Title)\n",
    "            ArtTest.append(Text)\n",
    "            ArtSummary.append(Summary)\n",
    "        else:\n",
    "            invalid_url.append(artLink)\n",
    "    print('Total News Articles Scrapped =', len(ArtTitle))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOI_Articles.to_csv(r'C:\\Users\\shrikanth\\Desktop\\University of Passau\\Text Mining Project\\Project Implementation\\CSV Files\\TOI\\TOI_II.csv', \n",
    "                    index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>NEW DELHI: Senior BJP leader and Union ministe...</td>\n",
       "      <td>NEW DELHI: Senior BJP leader and Union ministe...</td>\n",
       "      <td>Congress is creating 'political pollution': Naqvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Read the full articleJoin us and get access to...</td>\n",
       "      <td>Read the full article\\n\\nJoin us and get acces...</td>\n",
       "      <td>How politics is changing office politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>Lucknow: The Congress party on Sunday said tha...</td>\n",
       "      <td>Lucknow: The Congress party on Sunday said tha...</td>\n",
       "      <td>‘Cases against Lallu politically motivated’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Spats over ideology are rising in the workplac...</td>\n",
       "      <td>Spats over ideology are rising in the workplac...</td>\n",
       "      <td>How politics is changing office politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Manipur assembly speaker Yumnam Khemchand Sing...</td>\n",
       "      <td>Manipur assembly speaker Yumnam Khemchand Sing...</td>\n",
       "      <td>Yumnam Khemchand Singh: Opposition submits not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Summary  \\\n",
       "1543  NEW DELHI: Senior BJP leader and Union ministe...   \n",
       "1544  Read the full articleJoin us and get access to...   \n",
       "1545  Lucknow: The Congress party on Sunday said tha...   \n",
       "1546  Spats over ideology are rising in the workplac...   \n",
       "1547  Manipur assembly speaker Yumnam Khemchand Sing...   \n",
       "\n",
       "                                                   Text  \\\n",
       "1543  NEW DELHI: Senior BJP leader and Union ministe...   \n",
       "1544  Read the full article\\n\\nJoin us and get acces...   \n",
       "1545  Lucknow: The Congress party on Sunday said tha...   \n",
       "1546  Spats over ideology are rising in the workplac...   \n",
       "1547  Manipur assembly speaker Yumnam Khemchand Sing...   \n",
       "\n",
       "                                                  Title  \n",
       "1543  Congress is creating 'political pollution': Naqvi  \n",
       "1544           How politics is changing office politics  \n",
       "1545        ‘Cases against Lallu politically motivated’  \n",
       "1546           How politics is changing office politics  \n",
       "1547  Yumnam Khemchand Singh: Opposition submits not...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOI_Articles.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_format = {'Title' : ArtTitle, 'Text' : ArtTest, 'Summary' : ArtSummary}\n",
    "my_df = pd.DataFrame(text_format)\n",
    "my_df.to_csv(r'C:\\Users\\shrikanth\\Desktop\\University of Passau\\Text Mining Project\\Project Implementation\\CSV Files\\TOI\\TOI_II.csv', \n",
    "            index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
